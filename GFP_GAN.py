# -*- coding: utf-8 -*-
"""Copy of GFPGAN_inference.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1glKLfQcIPD9A8_Xvy2mjRlg4oKlr__vh

# GFPGAN Inference Demo
### (No colorization; No CUDA extensions required)

[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)
[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)
[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)

## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior

GFPGAN is a blind face restoration algorithm towards real-world face images. <br>
It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>

If you want to use the paper model, please go to this [Colab Demo](https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing) for GFPGAN <a href="https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="google colab logo"></a>.

**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.

###Enjoy! :-)

<img src="https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg" width="800">

# New Section

# 1. Preparations
Before start, make sure that you choose
* Runtime Type = Python 3
* Hardware Accelerator = GPU

in the **Runtime** menu -> **Change runtime type**

Then, we clone the repository, set up the envrironment, and download the pre-trained model.
"""

# Commented out IPython magic to ensure Python compatibility.
# Clone GFPGAN and enter the GFPGAN folder
# %cd /content
!rm -rf GFPGAN
!git clone https://github.com/TencentARC/GFPGAN.git
# %cd GFPGAN

# Set up the environment
# Install basicsr - https://github.com/xinntao/BasicSR
# We use BasicSR for both training and inference
!pip install basicsr
# Install facexlib - https://github.com/xinntao/facexlib
# We use face detection and face restoration helper in the facexlib package
!pip install facexlib
# Install other depencencies
!pip install -r requirements.txt
!python setup.py develop
!pip install realesrgan  # used for enhancing the background (non-face) regions
# Download the pre-trained model
# !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models
# Now we use the V1.3 model for the demo
!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models



"""# 2. Upload Images / Use the demo images"""

# upload your own images
import os
from google.colab import files
import shutil

upload_folder = 'inputs/upload'

if os.path.isdir(upload_folder):
    shutil.rmtree(upload_folder)
os.mkdir(upload_folder)

# upload images
uploaded = files.upload()
for filename in uploaded.keys():
  dst_path = os.path.join(upload_folder, filename)
  print(f'move {filename} to {dst_path}')
  shutil.move(filename, dst_path)

"""### OR you can use the demo image by running the following codes"""



"""## 3. Inference"""

# Read the content of the file
file_path = "/usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py"

with open(file_path, 'r') as file:
    content = file.readlines()

# Make your changes (replace 'functional_tensor' with 'functional')
new_content = [line.replace('functional_tensor', 'functional') for line in content]

# Write the modified content back to the file
with open(file_path, 'w') as file:
    file.writelines(new_content)

print("File modified successfully!")

"""## 4. Visualize"""

# Now we use the GFPGAN to restore the above low-quality images
# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions
# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo
!rm -rf results
!python inference_gfpgan.py -i inputs/upload -o results -v 1.3 -s 2 --bg_upsampler realesrgan

# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...
#
#  -h                   show this help
#  -i input             Input image or folder. Default: inputs/whole_imgs
#  -o output            Output folder. Default: results
#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3
#  -s upscale           The final upsampling scale of the image. Default: 2
#  -bg_upsampler        background upsampler. Default: realesrgan
#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400
#  -suffix              Suffix of the restored faces
#  -only_center_face    Only restore the center face
#  -aligned             Input are aligned faces
#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto

!ls results/cmp



"""Download Results"""

import shutil
import os

# Define the folder to be zipped
folder_path = 'results'  # Replace with your folder path

# Define the output zip file path (without .zip extension)
output_zip = 'downloads/result'  # The zip file will be saved here
if os.path.isdir(output_zip):
    shutil.rmtree(output_zip)
os.mkdir(output_zip)

# Create a zip file from the folder
shutil.make_archive(output_zip, 'zip', folder_path)

print(f"Folder '{folder_path}' has been zipped as '{output_zip}.zip'")

import cv2
import numpy as np

def calculate_psnr(original, restored):
    mse = np.mean((original - restored) ** 2)
    if mse == 0:
        return float('inf')  # No noise, perfect match
    max_pixel = 255.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
    return psnr



from skimage.metrics import structural_similarity as ssim
import cv2

def calculate_ssim(original, restored):
    # Ensure the images are grayscale
    original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
    restored_gray = cv2.cvtColor(restored, cv2.COLOR_BGR2GRAY)
    score, _ = ssim(original_gray, restored_gray, full=True)
    return score

import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim

def resize_image(image, target_shape):
    return cv2.resize(image, (target_shape[1], target_shape[0]))

# Load original and generated (restored) images
original = cv2.imread('inputs/upload/damagedbefore.jpeg')
restored = cv2.imread('results/cmp/damagedbefore_00.png')

# Resize restored image to match the shape of the original image
restored_resized = resize_image(restored, original.shape)

# Calculate PSNR
psnr_value = calculate_psnr(original, restored_resized)
print(f"PSNR: {psnr_value}")

# Calculate SSIM
ssim_value = calculate_ssim(original, restored_resized)
print(f"SSIM: {ssim_value}")

import cv2
import os
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

def resize_image(image, target_shape):
    return cv2.resize(image, (target_shape[1], target_shape[0]))

# Directories containing original and restored images
original_dir = 'inputs/upload/'
restored_dir = 'results/cmp/'

# Initialize lists to store PSNR and SSIM values
psnr_values = []
ssim_values = []

# Iterate over all files in the original images directory
for filename in os.listdir(original_dir):
    if filename.endswith((".png", ".jpg", ".jpeg")):  # Process image files only
        # Load the original and corresponding restored image
        original_path = os.path.join(original_dir, filename)
        restored_path = os.path.join(restored_dir, filename)  # Ensure filenames match

        # Check if the restored image exists
        if not os.path.exists(restored_path):
            print(f"Restored image not found for {filename}")
            continue

        # Read the original and restored images
        original_image = cv2.imread(original_path)
        restored_image = cv2.imread(restored_path)

        # Resize the restored image to match the original image
        restored_resized = resize_image(restored_image, original_image.shape)

        # Calculate PSNR
        psnr_value = psnr(original_image, restored_resized)
        psnr_values.append(psnr_value)

        # Calculate SSIM
        ssim_value = ssim(original_image, restored_resized, multichannel=True)
        ssim_values.append(ssim_value)

        # Print PSNR and SSIM for each image
        print(f"Image: {filename}, PSNR: {psnr_value}, SSIM: {ssim_value}")

# Calculate average PSNR and SSIM over all images
average_psnr = sum(psnr_values) / len(psnr_values) if psnr_values else 0
average_ssim = sum(ssim_values) / len(ssim_values) if ssim_values else 0

print(f"\nAverage PSNR: {average_psnr}")
print(f"Average SSIM: {average_ssim}")

import cv2
import os
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

def resize_image(image, target_shape):
    return cv2.resize(image, (target_shape[1], target_shape[0]))

# Directories containing original and restored images
original_dir = 'inputs/upload/'
restored_dir = 'results/cmp/'

# Initialize lists to store PSNR and SSIM values
psnr_values = []
ssim_values = []

# Function to find corresponding restored image by partial matching
def find_restored_image(original_filename, restored_dir):
    original_name = os.path.splitext(original_filename)[0]  # Get name without extension
    for restored_filename in os.listdir(restored_dir):
        if original_name in restored_filename:  # Partial match condition
            return os.path.join(restored_dir, restored_filename)
    return None

# Iterate over all files in the original images directory
for original_filename in os.listdir(original_dir):
    if original_filename.endswith((".png", ".jpg", ".jpeg")):  # Process image files only
        # Load the original image
        original_path = os.path.join(original_dir, original_filename)
        original_image = cv2.imread(original_path)

        # Find the corresponding restored image by partial match
        restored_path = find_restored_image(original_filename, restored_dir)

        # Check if the restored image was found
        if not restored_path:
            print(f"Restored image not found for {original_filename}")
            continue

        # Read the restored image
        restored_image = cv2.imread(restored_path)

        # Resize the restored image to match the original image
        restored_resized = resize_image(restored_image, original_image.shape)

        # Calculate PSNR
        psnr_value = psnr(original_image, restored_resized)
        psnr_values.append(psnr_value)

        # Calculate SSIM
        ssim_value = ssim(original_image, restored_resized, multichannel=True)
        ssim_values.append(ssim_value)

        # Print PSNR and SSIM for each image
        print(f"Image: {original_filename}, Restored: {os.path.basename(restored_path)}, PSNR: {psnr_value}, SSIM: {ssim_value}")

# Calculate average PSNR and SSIM over all images
average_psnr = sum(psnr_values) / len(psnr_values) if psnr_values else 0
average_ssim = sum(ssim_values) / len(ssim_values) if ssim_values else 0

print(f"\nAverage PSNR: {average_psnr}")
print(f"Average SSIM: {average_ssim}")

import cv2
import os
from glob import glob
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

def resize_image(image, target_shape):
    return cv2.resize(image, (target_shape[1], target_shape[0]))

# Directories containing original and restored images
original_dir = 'inputs/upload/'
restored_dir = 'results/cropped_faces/'

# Initialize lists to store PSNR and SSIM values
psnr_values = []
ssim_values = []

# Use glob to get all image files with specific extensions
original_images = glob(original_dir + '*.[pjPj][pnPN][gG]')  # Matches jpg, png, jpeg files
restored_images = glob(restored_dir + '*.[pjPj][pnPN][gG]')

# Function to find corresponding restored image by partial matching
def find_restored_image(original_filename, restored_images):
    original_name = os.path.splitext(os.path.basename(original_filename))[0]  # Get name without extension
    for restored_image_path in restored_images:
        restored_name = os.path.splitext(os.path.basename(restored_image_path))[0]
        if original_name in restored_name:  # Partial match condition
            return restored_image_path
    return None

# Iterate over all original images
for original_path in original_images:
    # Load the original image
    original_image = cv2.imread(original_path)

    # Find the corresponding restored image by partial match
    restored_path = find_restored_image(original_path, restored_images)

    # Check if the restored image was found
    if not restored_path:
        print(f"Restored image not found for {os.path.basename(original_path)}")
        continue

    # Read the restored image
    restored_image = cv2.imread(restored_path)

    # Resize the restored image to match the original image
    restored_resized = resize_image(restored_image, original_image.shape)

    # Calculate PSNR
    psnr_value = psnr(original_image, restored_resized)
    psnr_values.append(psnr_value)

    # Calculate SSIM
    ssim_value = ssim(original_image, restored_resized, multichannel=True)
    ssim_values.append(ssim_value)

    # Print PSNR and SSIM for each image
    print(f"Image: {os.path.basename(original_path)}, Restored: {os.path.basename(restored_path)}, PSNR: {psnr_value}, SSIM: {ssim_value}")

# Calculate average PSNR and SSIM over all images
average_psnr = sum(psnr_values) / len(psnr_values) if psnr_values else 0
average_ssim = sum(ssim_values) / len(ssim_values) if ssim_values else 0

print(f"\nAverage PSNR: {average_psnr}")
print(f"Average SSIM: {average_ssim}")

# We first visualize the cropped faces
# The left are the inputs images; the right are the results of GFPGAN

import cv2
import matplotlib.pyplot as plt
def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1)
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('GFPGAN output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)
def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img

# display each image in the upload folder
import os
import glob

input_folder = 'results/cropped_faces'
result_folder = 'results/restored_faces'
input_list = sorted(glob.glob(os.path.join(input_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))
for input_path, output_path in zip(input_list, output_list):
  img_input = imread(input_path)
  img_output = imread(output_path)
  display(img_input, img_output)

# We first visualize the cropped faces
# The left are the inputs images; the right are the results of GFPGAN

import cv2
import matplotlib.pyplot as plt
def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1)
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('GFPGAN output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)
def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img

# display each image in the upload folder
import os
import glob

input_folder = 'results/cropped_faces'
result_folder = 'results/restored_faces'
input_list = sorted(glob.glob(os.path.join(input_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))
for input_path, output_path in zip(input_list, output_list):
  img_input = imread(input_path)
  img_output = imread(output_path)
  display(img_input, img_output)

# We then visualize the whole image
# The left are the inputs images; the right are the results of GFPGAN

import cv2
import matplotlib.pyplot as plt
def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1)
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('GFPGAN output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)
def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img

# display each image in the upload folder
import os
import glob

input_folder = 'inputs/upload'
result_folder = 'results/restored_imgs'
input_list = sorted(glob.glob(os.path.join(input_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))
for input_path, output_path in zip(input_list, output_list):
  img_input = imread(input_path)
  img_output = imread(output_path)
  display(img_input, img_output)



# Now we use the GFPGAN to restore the above low-quality images
# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions
# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo
!rm -rf results
!python inference_gfpgan.py -i inputs/cropped_faces -o results -v 1.3 -s 2 --bg_upsampler realesrgan

# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...
#
#  -h                   show this help
#  -i input             Input image or folder. Default: inputs/whole_imgs
#  -o output            Output folder. Default: results
#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3
#  -s upscale           The final upsampling scale of the image. Default: 2
#  -bg_upsampler        background upsampler. Default: realesrgan
#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400
#  -suffix              Suffix of the restored faces
#  -only_center_face    Only restore the center face
#  -aligned             Input are aligned faces
#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto

!ls results/cmp

# We then visualize the whole image
# The left are the inputs images; the right are the results of GFPGAN

import cv2
import matplotlib.pyplot as plt
def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1)
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('GFPGAN output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)
def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img

# display each image in the upload folder
import os
import glob

input_folder = 'inputs/cropped_faces/'
result_folder = 'results/restored_imgs'
input_list = sorted(glob.glob(os.path.join(input_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))
for input_path, output_path in zip(input_list, output_list):
  img_input = imread(input_path)
  img_output = imread(output_path)
  display(img_input, img_output)

import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
import os
from math import log10, sqrt
from skimage import img_as_float
from scipy.stats import entropy

# Function to calculate PSNR
def calculate_psnr(original, restored):
    mse = np.mean((original - restored) ** 2)
    if mse == 0:
        return 100  # Means no noise, perfect image
    max_pixel = 255.0
    psnr_value = 20 * log10(max_pixel / sqrt(mse))
    return psnr_value

# Function to calculate MSE
def calculate_mse(original, restored):
    mse = np.mean((original - restored) ** 2)
    return mse

# Function to calculate SSIM
def calculate_ssim(original, restored):
    # Convert images to grayscale if they are RGB
    if len(original.shape) == 3:
        original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        restored = cv2.cvtColor(restored, cv2.COLOR_BGR2GRAY)

    ssim_value, _ = ssim(original, restored, full=True)
    return ssim_value

# Function to calculate Perceptual Index (PI) - Using Entropy for simplicity
def calculate_pi(original, restored):
    # Convert images to float
    original = img_as_float(original)
    restored = img_as_float(restored)

    # Compute entropy
    original_entropy = entropy(original.ravel())
    restored_entropy = entropy(restored.ravel())

    # Calculate the perceptual index (difference in entropy)
    pi_value = abs(original_entropy - restored_entropy)
    return pi_value

# Folder paths for comparison
restored_folder = 'results/cmp'  # The folder with restored images
original_folder = 'inputs/upload'  # The folder with original images

# List of images in both folders
restored_images = os.listdir(restored_folder)
original_images = os.listdir(original_folder)

psnr_total = 0
mse_total = 0
ssim_total = 0
pi_total = 0

# Loop through each image, calculate metrics, and accumulate values
for restored_image_name in restored_images:
    # Match restored image with the original image
    original_image_name = restored_image_name  # Assuming same name for original and restored
    if original_image_name in original_images:
        restored_image = cv2.imread(os.path.join(restored_folder, restored_image_name))
        original_image = cv2.imread(os.path.join(original_folder, original_image_name))

        # Calculate PSNR
        psnr_value = calculate_psnr(original_image, restored_image)
        psnr_total += psnr_value

        # Calculate MSE
        mse_value = calculate_mse(original_image, restored_image)
        mse_total += mse_value

        # Calculate SSIM
        ssim_value = calculate_ssim(original_image, restored_image)
        ssim_total += ssim_value

        # Calculate PI (using entropy difference here)
        pi_value = calculate_pi(original_image, restored_image)
        pi_total += pi_value

# Calculate the average values
num_images = len(restored_images)
average_psnr = psnr_total / num_images
average_mse = mse_total / num_images
average_ssim = ssim_total / num_images
average_pi = pi_total / num_images

# Print out the results
print(f"Average MSE: {average_mse}")
print(f"Average PSNR: {average_psnr}")
print(f"Average SSIM: {average_ssim}")
print(f"Average PI: {average_pi}")

import cv2
import numpy as np
import os
import glob
from skimage.metrics import structural_similarity as ssim
from math import log10, sqrt
from skimage import img_as_float
from scipy.stats import entropy

# Function to calculate PSNR
def calculate_psnr(original, restored):
    mse = np.mean((original - restored) ** 2)
    if mse == 0:
        return 100  # Perfect match
    max_pixel = 255.0
    psnr_value = 20 * log10(max_pixel / sqrt(mse))
    return psnr_value

# Function to calculate MSE
def calculate_mse(original, restored):
    mse = np.mean((original - restored) ** 2)
    return mse

# Function to calculate SSIM
def calculate_ssim(original, restored):
    if len(original.shape) == 3:
        original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        restored = cv2.cvtColor(restored, cv2.COLOR_BGR2GRAY)
    ssim_value, _ = ssim(original, restored, full=True)
    return ssim_value

# Function to calculate PI (Perceptual Index)
def calculate_pi(original, restored):
    original = img_as_float(original)
    restored = img_as_float(restored)
    original_entropy = entropy(original.ravel())
    restored_entropy = entropy(restored.ravel())
    pi_value = abs(original_entropy - restored_entropy)
    return pi_value

# Function to read images and convert to RGB
def imread(img_path):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img

# Displaying images side by side
def display(img1, img2):
    fig = plt.figure(figsize=(25, 10))
    ax1 = fig.add_subplot(1, 2, 1)
    plt.title('Input image', fontsize=16)
    ax1.axis('off')
    ax2 = fig.add_subplot(1, 2, 2)
    plt.title('GFPGAN output', fontsize=16)
    ax2.axis('off')
    ax1.imshow(img1)
    ax2.imshow(img2)

# Folder paths
input_folder = 'inputs/cropped_faces/'
result_folder = 'results/restored_imgs'

# List of input and output images
input_list = sorted(glob.glob(os.path.join(input_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))

# Initialize counters for PSNR, MSE, SSIM, and PI
psnr_total = 0
mse_total = 0
ssim_total = 0
pi_total = 0

# Iterate through the images and calculate metrics
for input_path, output_path in zip(input_list, output_list):
    img_input = imread(input_path)
    img_output = imread(output_path)

    # Resize the output image to match the input image size (if needed)
    if img_input.shape != img_output.shape:
        img_output = cv2.resize(img_output, (img_input.shape[1], img_input.shape[0]))

    # Calculate PSNR, MSE, SSIM, and PI for each pair
    psnr_value = calculate_psnr(img_input, img_output)
    mse_value = calculate_mse(img_input, img_output)
    ssim_value = calculate_ssim(img_input, img_output)
    pi_value = calculate_pi(img_input, img_output)

    # Accumulate the values
    psnr_total += psnr_value
    mse_total += mse_value
    ssim_total += ssim_value
    pi_total += pi_value

    # Optionally display the images
    display(img_input, img_output)

# Calculate average values for PSNR, MSE, SSIM, and PI
num_images = len(input_list)
average_psnr = psnr_total / num_images
average_mse = mse_total / num_images
average_ssim = ssim_total / num_images
average_pi = pi_total / num_images

# Print the average values
print(f"Average PSNR: {average_psnr}")
print(f"Average MSE: {average_mse}")
print(f"Average SSIM: {average_ssim}")
print(f"Average PI: {average_pi}")

import matplotlib.pyplot as plt

# GFP-GAN metrics
metrics = ['PSNR', 'MSE', 'SSIM', 'PI']
values = [32.6567, 36.8025, 0.8385, 0.0045]  # Replace with the actual values

# Create a bar chart
plt.figure(figsize=(10, 6))
bars = plt.bar(metrics, values, color=['blue', 'green', 'orange', 'purple'])

# Add data labels on top of each bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.2, round(yval, 4), ha='center', va='bottom')

# Graph aesthetics
plt.title('Performance Metrics for GFP-GAN Model', fontsize=16)
plt.xlabel('Metrics', fontsize=14)
plt.ylabel('Values', fontsize=14)
plt.ylim(0, max(values) + 5)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.show()